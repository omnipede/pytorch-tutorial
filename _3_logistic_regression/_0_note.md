# 로지스틱 회귀

## 로지스틱 회귀란

입력 데이터에 대한 출력 데이터의 종류가 두 가지 인 경우 이진 분류라고 한다. 메일이 스팸메일인지 아닌지 구분하는 문제를 예로 들 수 있다.
이진 분류 문제를 해결하기 위한 대표적인 알고리즘이 로지스틱 회귀다.

## 시그모이드 함수

로지스틱 회귀 문제의 가설 H(x) 는 다음과 같이 정의한다.

```markdown
H(x) = sigmoid(Wx + b)
```

```sigmoid``` 를 씌우는 이유는 출력값이 참/거짓 으로 이분화되기 때문이다. 즉 가설 H(x) 는 0 ~ 1 사이의 값을 갖는다.  
실제값 y 가 1일 때 예측값 H(x) 가 0에 가까우면 오차가 커져야 하고 y 가 0 일 때 예측값 H(x) 가 1에 가까우면 오차가 커져야 한다.
위 조건을 만족하는 함수는 로그함수다. 수식으로 분류하면 다음과 같다.

```markdown
if y = 1,
    loss = -log(H(x))
if y = 0,
    loss = -log(1 - H(x))
```

좀 더 일반적으로 식을 다음으면

```markdown
loss = -(y * log(H(x)) + (1 - y) * log(1 - H(x)))
```

가 되고, 모든 훈련 데이터에 대한 오차의 평균을 비용이라고 할 수 있다.

![스크린샷 2022-02-04 오후 5 02 42](https://user-images.githubusercontent.com/41066039/152493353-1b48615c-1c0d-428e-94ac-fbbb60abb7d3.png)

위 비용함수에 대해 선형 회귀와 동일하게 경사 하강법을 적용하면 된다.